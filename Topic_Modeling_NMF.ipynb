{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSkbQVNSQDBRb6klyI4Jl7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkp74/Topic_Modelling/blob/main/Topic_Modeling_NMF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from time import time\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "mCy1FVViPnZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nmf(X, n_components, max_iter=1000, tol=1e-6):\n",
        "    # Random initialization of W and H\n",
        "    W = np.random.rand(X.shape[0], n_components)\n",
        "    H = np.random.rand(n_components, X.shape[1])\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        # Update H\n",
        "        H *= (W.T @ X) / (W.T @ (W @ H) + 1e-9)\n",
        "\n",
        "        # Update W\n",
        "        W *= (X @ H.T) / ((W @ H) @ H.T + 1e-9)\n",
        "\n",
        "        # Compute the Frobenius norm as the error\n",
        "        error = np.linalg.norm(X - W @ H, 'fro')\n",
        "\n",
        "        if error < tol:\n",
        "            print(f\"Converged after {i + 1} iterations.\")\n",
        "            break\n",
        "\n",
        "    return W, H\n"
      ],
      "metadata": {
        "id": "B1voCKN6CA6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 15\n",
        "n_top_words = 5\n",
        "batch_size = 128\n"
      ],
      "metadata": {
        "id": "Hq7OP_1cWVlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and preprocess the data\n",
        "print(\"Loading dataset...\")\n",
        "t0 = time()\n",
        "data, _ = fetch_20newsgroups(\n",
        "    shuffle=True,\n",
        "    random_state=1,\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    return_X_y=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AAGEVqmWWHw",
        "outputId": "77f691e2-9c63-437f-8492-2eebe0800648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_samples = data[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPlyphuLWaJL",
        "outputId": "c8dd9a72-edac-4f8b-d736-d774380ebdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done in 2.981s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tf-idf features for training the NMF\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\")\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples).toarray().T\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJCBgXF2Wcsx",
        "outputId": "a1c2d430-2076-4edf-9c66-b60e287c7c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting tf-idf features for NMF...\n",
            "done in 0.403s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform NMF\n",
        "print(\"Performing NMF...\")\n",
        "W, H = nmf(tfidf, n_components, max_iter=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ_-pyOnWgup",
        "outputId": "10aa2b6c-56fe-41a0-8854-eff9594a674a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing NMF...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_topics(W, H, feature_names, n_top_words):\n",
        "    num_topics = W.shape[1]\n",
        "\n",
        "    for topic_idx in range(num_topics):\n",
        "        # Ensure indices are within the valid range\n",
        "        top_features_ind = np.argsort(W[:, topic_idx])[::-1][:n_top_words]\n",
        "        top_features_ind = top_features_ind[top_features_ind < len(feature_names)]\n",
        "\n",
        "        top_features = feature_names[top_features_ind]\n",
        "        weights = W[top_features_ind, topic_idx]\n",
        "\n",
        "        print(f\"Topic {topic_idx + 1}:\")\n",
        "        for feature, weight in zip(top_features, weights):\n",
        "            print(f\"{feature}: {weight:.4f}\")\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "D4A9Fd-tO4r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract topics using the learned NMF-like components\n",
        "tfidf_feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
        "extract_topics(W, H, tfidf_feature_names, n_top_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE7zXNdkO83J",
        "outputId": "38f31afa-03a3-499a-e295-c094773889d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1:\n",
            "people: 30.6011\n",
            "law: 9.1338\n",
            "government: 9.0207\n",
            "did: 8.9991\n",
            "israel: 8.4803\n",
            "\n",
            "\n",
            "Topic 2:\n",
            "thanks: 34.2172\n",
            "know: 21.5730\n",
            "does: 19.8200\n",
            "mail: 15.0363\n",
            "advance: 14.5057\n",
            "\n",
            "\n",
            "Topic 3:\n",
            "god: 46.2602\n",
            "jesus: 12.5687\n",
            "bible: 10.7995\n",
            "faith: 7.9381\n",
            "does: 7.2693\n",
            "\n",
            "\n",
            "Topic 4:\n",
            "car: 37.1527\n",
            "bike: 17.7268\n",
            "good: 12.1376\n",
            "cars: 10.9247\n",
            "engine: 7.4437\n",
            "\n",
            "\n",
            "Topic 5:\n",
            "space: 28.8470\n",
            "nasa: 10.0659\n",
            "data: 8.4348\n",
            "earth: 8.1463\n",
            "book: 7.9802\n",
            "\n",
            "\n",
            "Topic 6:\n",
            "game: 31.6287\n",
            "team: 16.6582\n",
            "year: 14.0987\n",
            "games: 13.3489\n",
            "play: 9.7267\n",
            "\n",
            "\n",
            "Topic 7:\n",
            "drive: 37.2247\n",
            "drives: 14.7257\n",
            "hard: 12.5856\n",
            "disk: 11.7736\n",
            "software: 9.5968\n",
            "\n",
            "\n",
            "Topic 8:\n",
            "windows: 33.6943\n",
            "file: 22.8666\n",
            "dos: 12.1325\n",
            "using: 10.9816\n",
            "use: 10.6158\n",
            "\n",
            "\n",
            "Topic 9:\n",
            "edu: 48.8971\n",
            "soon: 10.9706\n",
            "com: 9.4081\n",
            "send: 6.0648\n",
            "university: 5.4261\n",
            "\n",
            "\n",
            "Topic 10:\n",
            "00: 32.9821\n",
            "10: 15.2739\n",
            "sale: 13.7677\n",
            "card: 8.7801\n",
            "price: 8.4137\n",
            "\n",
            "\n",
            "Topic 11:\n",
            "key: 27.6103\n",
            "chip: 20.9733\n",
            "clipper: 15.4195\n",
            "keys: 13.5475\n",
            "encryption: 13.2521\n",
            "\n",
            "\n",
            "Topic 12:\n",
            "like: 46.6235\n",
            "don: 13.9964\n",
            "sounds: 11.1396\n",
            "know: 9.3137\n",
            "look: 7.0069\n",
            "\n",
            "\n",
            "Topic 13:\n",
            "just: 49.2100\n",
            "thought: 7.9971\n",
            "ll: 7.3178\n",
            "sure: 7.2070\n",
            "wrong: 5.9816\n",
            "\n",
            "\n",
            "Topic 14:\n",
            "ve: 39.9356\n",
            "got: 21.6571\n",
            "seen: 9.5436\n",
            "try: 6.6045\n",
            "times: 5.5268\n",
            "\n",
            "\n",
            "Topic 15:\n",
            "think: 50.8974\n",
            "don: 10.7480\n",
            "good: 4.7683\n",
            "need: 4.5063\n",
            "use: 4.3006\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_word_clouds(W, feature_names, n_top_words, output_dir=\"word_clouds\"):\n",
        "    # Create an output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    num_topics = W.shape[1]\n",
        "\n",
        "    for topic_idx in range(num_topics):\n",
        "        # Get the top words for the current topic\n",
        "        top_features_ind = np.argsort(W[:, topic_idx])[::-1][:n_top_words]\n",
        "\n",
        "        # Ensure the indices are within the valid range of feature_names\n",
        "        valid_top_features_ind = top_features_ind[top_features_ind < len(feature_names)]\n",
        "        top_features = [feature_names[i] for i in valid_top_features_ind]\n",
        "        weights = [W[i, topic_idx] for i in valid_top_features_ind]\n",
        "\n",
        "        # Create a dictionary of words and their weights for the word cloud\n",
        "        wordcloud_data = {top_features[i]: weights[i] for i in range(len(top_features))}\n",
        "\n",
        "        # Create and save the word cloud for the current topic\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(wordcloud_data)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.title(f'Topic {topic_idx + 1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Save the word cloud as an image\n",
        "        image_file = os.path.join(output_dir, f\"topic_{topic_idx + 1}_wordcloud.png\")\n",
        "        plt.savefig(image_file)\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "FNsc3LqHPEXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the visualize_word_clouds function\n",
        "visualize_word_clouds(W, tfidf_feature_names, n_top_words)"
      ],
      "metadata": {
        "id": "yz4o2uujPejR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_coherence(W, feature_names, texts, n_top_words):\n",
        "    num_topics = W.shape[1]\n",
        "\n",
        "    # Ensure valid indices and adjust n_top_words if needed\n",
        "    n_top_words = min(n_top_words, len(feature_names))\n",
        "\n",
        "    # Extract top words for each topic\n",
        "    top_words_per_topic = []\n",
        "    for topic_idx in range(num_topics):\n",
        "        top_features_ind = np.argsort(W[:, topic_idx])[::-1][:n_top_words]\n",
        "        top_words = [feature_names[i] for i in top_features_ind if i < len(feature_names)]\n",
        "        top_words_per_topic.append(top_words)\n",
        "\n",
        "    # Create a CountVectorizer to convert text to a bag of words\n",
        "    vectorizer = CountVectorizer(vocabulary=feature_names, binary=True)\n",
        "    bow_matrix = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "    # Calculate co-occurrence matrix (word by word)\n",
        "    co_occurrence_matrix = np.dot(bow_matrix.T, bow_matrix)\n",
        "    np.fill_diagonal(co_occurrence_matrix, 0)\n",
        "\n",
        "    # Initialize coherence\n",
        "    coherence = 2.0\n",
        "\n",
        "    # Calculate coherence for each topic\n",
        "    for topic_words in top_words_per_topic:\n",
        "        topic_coherence = 0.0\n",
        "        for i in range(len(topic_words)):\n",
        "            for j in range(i + 1, len(topic_words)):\n",
        "                word_i, word_j = topic_words[i], topic_words[j]\n",
        "                if word_i in feature_names and word_j in feature_names:\n",
        "                    word_i_idx, word_j_idx = np.where(feature_names == word_i)[0], np.where(feature_names == word_j)[0]\n",
        "                    if len(word_i_idx) > 0 and len(word_j_idx) > 0:\n",
        "                        co_occurrences = co_occurrence_matrix[word_i_idx[0], word_j_idx[0]]\n",
        "                        word_i_freq = np.sum(bow_matrix[:, word_i_idx])\n",
        "                        word_j_freq = np.sum(bow_matrix[:, word_j_idx])\n",
        "\n",
        "                        # Compute Pointwise Mutual Information (PMI)\n",
        "                        pmi = np.log((co_occurrences * len(texts)) / (word_i_freq * word_j_freq) + 1e-10)\n",
        "                        topic_coherence += pmi\n",
        "\n",
        "        # Average over word pairs\n",
        "        topic_coherence /= len(topic_words)\n",
        "        coherence += topic_coherence\n",
        "\n",
        "    # Average over topics\n",
        "    coherence /= num_topics\n",
        "\n",
        "    return coherence\n",
        "\n"
      ],
      "metadata": {
        "id": "MZ4EMqRCPhw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function to calculate coherence\n",
        "coherence = calculate_coherence(W, tfidf_feature_names, data_samples, n_top_words)\n",
        "print(f\"Coherence: {coherence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOLd7U3hPz9h",
        "outputId": "5b18ea28-ad20-40ca-b05a-4533a369c510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence: 2.818793743908425\n"
          ]
        }
      ]
    }
  ]
}